# AHFAL: Adaptive Hierarchical Federated Active Learning


### Installation
```bash
pip install -r requirements.txt
```

## âš™ï¸ Configuration

### Default Settings
```python
CLIENTS = 10        # Federated clients
ALPHA = 0.1         # Dirichlet non-IID parameter  
CYCLES = 6          # Active learning cycles
BUDGET = 2500       # Labels per cycle
BASE = 5000         # Initial labeled samples
EPOCHS = 5          # Local training epochs
COMMUNICATION = 100   # FL communication rounds
```

### Key Parameters
```bash
--strategy {AHFAL,KAFAL,Entropy,BADGE,Random}  # Active learning method
--dataset {CIFAR10,CIFAR100,SVHN,MNIST}        # Dataset choice
--clients N          # Number of federated clients (default: 10)
--alpha FLOAT        # Non-IID level (default: 0.1, lower = more non-IID)
--cycles N           # Active learning cycles (default: 3)
--budget N           # Samples to label per cycle (default: 2500)
--seed N             # Random seed for reproducibility
--save-checkpoints   # Enable model checkpointing (optional)
```


## ğŸ“ Repository Structure

```
FAL/
â”œâ”€â”€ ğŸ“„ main.py                    # Main experiment entry point
â”œâ”€â”€ âš™ï¸ config.py                  # Global configuration
â”œâ”€â”€ ğŸ“‹ requirements.txt           # Dependencies
â”œâ”€â”€ ğŸ§  query_strategies/          # Active learning methods
â”‚   â”œâ”€â”€ ğŸŒŸ AHFAL.py              # Our proposed method
â”‚   â”œâ”€â”€ ğŸ“Š kafal.py               # KAFAL baseline
â”‚   â”œâ”€â”€ ğŸ¯ entropy.py             # Entropy sampling
â”‚   â”œâ”€â”€ ğŸª badge.py               # BADGE sampling
â”‚   â””â”€â”€ ğŸ² random.py              # Random baseline
|   |__ ...
â”œâ”€â”€ ğŸ‹ï¸ training/                  # Federated learning framework
â”‚   â”œâ”€â”€ trainer.py               # Main FL trainer
â”‚   â”œâ”€â”€ evaluation.py            # Model evaluation
â”‚   â””â”€â”€ utils.py                 # Training utilities
â”œâ”€â”€ ğŸ—ï¸ models/                   # Neural architectures
â”œâ”€â”€ ğŸ“Š data/                     # Data partitioning
â”œâ”€â”€ ğŸ“ˆ analysis/                 # Logging utilities
â””â”€â”€ ğŸ“ analysis_logs/            # Experiment results (JSON)
```

---

## ğŸ’¾ Output & Results

### Experiment Logs
Results are automatically saved to `analysis_logs/` as JSON files containing:
- âœ… Global model accuracy per cycle
- ğŸ“Š Per-class accuracy breakdown  
- ğŸ¯ Sample selection statistics
- ğŸ“ˆ Class distribution analysis

### Example Output File
```
analysis_logs/AHFAL_c10_trial1.json
```

---
## ğŸ”¬ Reproducibility

### Deterministic Execution
-  All experiments use comprehensive seeding 
- Results are deterministic given same environment
- We used seed 44 for the first trial of each experiment
